{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and evaluating"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse and conclude\n",
    "Here is an example of some data and the neural network's prediction:\n",
    "\n",
    "![image.png](imgs/image.png)\n",
    "\n",
    "And even though the input data is very noisy, it still manages to get a close prediction! The reason it looks more straight is if it were to predict a jagged line that was the opposite way (instead of `/\\` it did `\\/`) then it would be *double* as wrong as it would have been if it just predicted an average-like line (`--`). This demonstrates the capability to learn that this NN has! The predicted weather is usually ~3â„ƒ off, but usually ranges from 1-5â„ƒ. This isn't that far off!\n",
    "\n",
    "How it accomplishes the predicting is by a `Sequential` AI model, with an LSTM layer and a Dense layer. The LSTM layer is basically like a memory - it learns long-term sequence patterns. This helps make it more accurate to long-term data. The Dense layer is a regular neural network layer with nodes. These combined make the neural network which predict the weather.\n",
    "\n",
    "In the end, I found this data can be used to predict what the weather will be and can help plan your day. I also discovered that predicting the weather is much harder than I thought. This is exactly as I hoped for! Originally I had in mind I would predict all the jaggedness I was talking about, but in the end it just a simple line; but I realised that that's for the best! And if it were integrated into something like a smartphone's home screen through it's api, it could be easily adopted for everyday usage!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peer Evaluation\n",
    "### Riley\n",
    "> The graph is pretty fast to load but the AI does take some time but it is a given as AI's aren't the fastest and it's a difficult process. The data stores really well.\n",
    "> The user interface is clean and goes above and beyond and even includes a switch to change from light and dark mode which is a nice quality of life featurn as someone who enjoys dark mode.\n",
    "> The data is impressively visualised with an interactive plot which is pretty easy to read and judge and it's incredibly impressive that an AI is built in to predict data and it also is astoundly close to the true data.\n",
    "> It cleans all of the data and has interactibility which makes it easier to access and look at the data.\n",
    "> Max ticks the criteria in allowing his program to be called as an Api. The program catches all errors well and its reliable and no errors will be displayed anyway. \n",
    "> Overall Max has addressed all of his functional and nonfunctional requirements.The readme is clear but the library he used is difficult to download. He went above and beyond and smashed through all of his criteria in an impressively optimised program with annotation. \n",
    "### Viggo\n",
    "> The graph loads speebibly and the AI works incredibly well. Data prediction is verry acruate and the dark mode is a nice touch. I like how easy this program is to use as well as how well it does its job. Data is very easy to visualiise and read. I like this program it is megapog. Max are you still reading? This program executees all requirements perfectly.\n",
    "\n",
    "### Evaluation on the peer review\n",
    "From the peer review, I see that I have done well and agree with them that I have executed all the functional requirements correctly. I have learnt that people like a pretty UI, and that the GUI with it's liight and dark mode switch was a very good idea; and I agree. Also with Riley's comment about it not being the fastest - I noticed that and it made testing more annoying but it can't be fixed - it's as fast as I can get it to be. All the time waiting was for it to download, unzip or train - things which can't really be made much faster. This means that for the final product I understand that it may be hard for people to install it due to tensorflow and take a long time to use, but ignoring that this project is amazing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Final Product in Relation to Functional and Non-Functional Requirements\n",
    "In terms of non-functional requirements, my app astounds; but some things unavoidably can't be as good as the overly-confident requirements outline them to be. With asthetics, the app was designed nicely with a good user interface, nice icons and a light and dark theme; all of which improved the user happiness from using the app and made it much more friendly and easy to use. <small>(Also more cool to show off ðŸ˜ˆ). </small>With reliability; the project continues to meet the requirements - I coded in error handling to make everyone sure when there are errors and make it easy to debug.\n",
    "\n",
    "![User interface image](imgs/image5.png)\n",
    "\n",
    "With usability and accuracy, the neural network highlights how far we've come in computing power and proves that it can accurately predict the weather. With usability; running the app is easy and the installation is super simple for everything - ***<u>EXCEPT TENSORFLOW</u>***. Tensorflow can be a big pain to install, giving many warnings and throwing import errors all over the place. Once it took me half an hour to get it working. It constantly complains and I don't like it; but when you get it installed and it doesn't throw an error you can just ignore any warnings and everything will run smoothly once more!\n",
    "\n",
    "![Example of how annoying tensorflow is](imgs/image8.png)\n",
    "\n",
    "And lastly, the speed isn't instantanious. It takes ages to download the data and another long time to unzip and clean everything and a little more time to train the AI. But I made it better; with caching so you don't have to redownload the datasets again (which is even more useful if you're offline) with an extensively tested system to make it easy to redownload or delete the existing cache or whatever else. I also added savestates so it saves the unzipped and cleaned data for a much faster time - ~20 seconds to load. Still better than the couple of minutes it would take to regularly clean the data. And I haven't implemented any savestates for the AI just yet.\n",
    "\n",
    "---\n",
    "\n",
    "And now moving onto functional requirements; with that regard, I did exceptionally well, with some improvements to be made of course. Starting off with data loading and cleaning; it correctly downloads, processes and cleans the data from the ftp site as well as constantly report it's progress in doing so and returning any errors that may have occured along the way. Everything there runs smoothly and correctly, with minimal errors (but with a wifi connection you should have avoided most of them).\n",
    "\n",
    "![Example error when I turn off my wifi](imgs/image7.png)\n",
    "\n",
    "For visualisation and analysis, the app does very well and makes it easy to analyse large amounts of data. In the UI, it creates a map of every weather station location and whether or not it has any data for it, and also can request a plot of specific data. It can plot both the temperature and rainfall datasets I currently have. For the visualisation I chose to use Bokeh instead of Matplotlib so it can be interactive on the Flask website, which is taken advantage of heavily through the hover tool on the map to show info about the place dot you have selected as well as making it super easy and simple to view any part of the data you want.\n",
    "\n",
    "![The map with all the locations](imgs/image6.png)\n",
    "\n",
    "With data storage, it can and will store downloaded files unless you ask not to and you can also save the cleaned data to make running the program again *much* faster. With regards to the API; I think I did well, but could be better. I currently only have endpoints for doing only what *my* app needs to do - and so adding more endpoints for doing other things like getting the data as well as getting a plot of the data would be better, as it means more things can be done with the API than just what I made it for; thus the point of wanting to make an API in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of your Project in Relation to Testing and Project Management\n",
    "I did pretty good with my testing of the app and also with my time management, but could improve. With time management, I did well - finishing before a lot of people were done; but I still could've done it all a lot earlier if I chose an easier task. It was a risk; if I failed, the task would have much worse quality and would not look as good, but if I suceeded (which I did) then it would turn out awesome! So because I love coding so much I took the risk to do something over the top and I'm glad I finished it. With problem solving and testing - I spent **hours** trying to get various things to work. Because I've done heaps of coding before most things worked on either the first, maybe second or third try. For any bugs that were hidden better (of which there were quite a few; no one is the best) there was much Googling to be done, but I fixed pretty much everything (or at least found it and put it on my todo list).\n",
    "\n",
    "![Temperature data example](imgs/image2.png)\n",
    "\n",
    "Some examples of challenges I faced were getting the FTP site to work as I've never used ftp sites before. It was OK, and with some sample code I got it working. Then it just took me a while to figure out what I needed to grab *from* the ftp site. That was annoying; there were so many files and folders! And once I got them I needed to unzip the .zip to get the .txt files inside, then unzip the .tar file to get the .Z files inside it and then unzip *those* with yet another library. Was a lot of work and different libraries trying to find what things I needed. It was also annoying trying to parse the files. They were not .csv files but rather were text files where all the data was separated by an arbitrary amount of spaces for each column of data and some columns had spaces in the data. I got over this by specially parsing the text using many regular expressions.\n",
    "\n",
    "![Rainfall data example](imgs/image3.png)\n",
    "\n",
    "Parsing the files wasn't the only hard challenge, but in addition to that and many others there was the challenge of making a neural network. At first, what made it even harder was the fact I've almost never made a neural network to do something practical before. So, to overcome this, I googled sample code to predict a sine wave and got that to work; then I tested it with noise to see what it would do and it did pretty well. Then I trained it on the weather data. I struggled finding layers that would make the model predict something that wasn't the straight line, but then realised that being straight is ok and used the original layers. Overall, there were many challenges but I overcame them.\n",
    "\n",
    "![AI prediction function output](imgs/image4.png)\n",
    "\n",
    "But all in all, I spent many hours working on this. I used pretty much all my train rides to and from school and even more time at home working on this project and I'm really glad it turned out well! There's still more I could do, but this is enough. I've squeezed out as much as I could've. Couldn't be happier with the product!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
